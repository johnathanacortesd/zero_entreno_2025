# Zero_Entreno_2025: Inferencia Avanzada de Tono y Tema en Noticias

Este proyecto de vanguardia se enfoca en la **clasificaci√≥n autom√°tica de texto** para el **an√°lisis de tono (sentimiento)** y la **categorizaci√≥n tem√°tica** de res√∫menes de noticias. Ofrece una soluci√≥n dual y flexible, capaz de operar tanto con un **enfoque "Zero-Shot" (sin entrenamiento expl√≠cito)** para una implementaci√≥n √°gil, como con un **enfoque basado en entrenamiento supervisado** utilizando datos manualmente codificados para alcanzar la m√°xima precisi√≥n en dominios espec√≠ficos.

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1x12TMUWPBT9lgqRBlZJcZssCOSNCopQ9#scrollTo=8T0NTLANOshM)

---

## ‚ú® Ventajas Clave del Proceso

La implementaci√≥n de este sistema de clasificaci√≥n autom√°tica genera beneficios sustanciales para cualquier organizaci√≥n que gestione vol√∫menes significativos de informaci√≥n textual:

### üöÄ 1. **Flexibilidad Estrat√©gica: Zero-Shot y Entrenamiento Supervisado**
El proyecto capitaliza lo mejor de ambos paradigmas en el PLN:
* **An√°lisis "Zero-Shot":** Permite la clasificaci√≥n de contenido de forma inmediata, sin la necesidad de un conjunto de datos de entrenamiento espec√≠fico para cada nueva categor√≠a. Esto es ideal para la exploraci√≥n r√°pida de temas emergentes o la categorizaci√≥n en dominios desconocidos.
* **Precisi√≥n con Entrenamiento Supervisado:** Para escenarios que demandan una alta fidelidad y donde existen datos hist√≥ricos etiquetados manualmente, el proyecto soporta la integraci√≥n de modelos entrenados. Esto afina la capacidad del sistema para comprender las particularidades l√©xicas y sem√°nticas de tu negocio o sector.

### üéØ 2. **Precisi√≥n y Consistencia Unificadas**
Independientemente del enfoque elegido, el sistema garantiza una **consistencia y precisi√≥n uniformes** en la clasificaci√≥n. Supera la variabilidad y los posibles sesgos introducidos por la clasificaci√≥n manual, asegurando un an√°lisis de datos objetivo y replicable a gran escala.

### üìà 3. **Eficiencia Operativa y Escalabilidad Masiva**
Automatiza la ingente tarea de analizar miles de documentos en cuesti√≥n de minutos. Esta capacidad libera a los equipos de la clasificaci√≥n manual repetitiva, permiti√©ndoles reorientar sus esfuerzos hacia an√°lisis estrat√©gicos y tareas de mayor valor a√±adido. El dise√±o del sistema est√° optimizado para el **aprovechamiento de Unidades de Procesamiento Gr√°fico (GPUs)**, lo que acelera significativamente el rendimiento computacional.

### üí∞ 4. **Optimizaci√≥n de Recursos y Reducci√≥n de Costos**
La automatizaci√≥n del an√°lisis de tono y tema conlleva una **minimizaci√≥n sustancial de los costos operativos** asociados a la mano de obra. La inversi√≥n en esta soluci√≥n se traduce en ahorros significativos a largo plazo y una asignaci√≥n m√°s eficiente de los recursos organizacionales.

### üí° 5. **Extracci√≥n de Insights Estrat√©gicos**
M√°s all√° de la mera clasificaci√≥n, este proceso facilita la **detecci√≥n de patrones, tendencias y opiniones ocultas** dentro de tus datos textuales. Permite:
* Identificar los temas de mayor impacto e inter√©s para tu audiencia o stakeholders.
* Comprender el sentimiento predominante hacia tu marca, productos, servicios o eventos clave.
* Detectar proactivamente problemas incipientes, identificar oportunidades de mejora o validar estrategias basadas en el feedback no estructurado.

---

## üìö Metodolog√≠as y Componentes T√©cnicos

Este proyecto integra dos metodolog√≠as principales para la clasificaci√≥n de texto:

### 1. **An√°lisis "Zero-Shot" (Inferencia sin Entrenamiento Espec√≠fico)**

Este enfoque se basa en el poder de los **modelos pre-entrenados de PLN** que ya han aprendido vastos patrones ling√º√≠sticos.
* **Concepto:** Se utilizan **embeddings sem√°nticos** para representar tanto los textos de entrada como las categor√≠as de inter√©s (sentimientos o temas). La clasificaci√≥n se realiza calculando la **similitud cosenoidal** entre el embedding del texto y los embeddings "prototipo" de cada categor√≠a.
* **Tono (Sentimiento):**
    * **Modelo:** Se emplea `pysentimiento/robertuito-sentiment-analysis`, un modelo **Sentence-BERT** altamente robusto y p√∫blico, espec√≠ficamente fine-tuneado para el an√°lisis de sentimiento en espa√±ol.
    * **Funcionamiento:**
        * Los textos se preprocesan (normalizaci√≥n, limpieza de URLs y caracteres especiales).
        * Se definen palabras clave prototipo (`sentiment_keywords`) para "Positivo", "Neutro" y "Negativo".
        * Los textos se codifican en embeddings.
        * Se calcula la similitud cosenoidal con los embeddings de las categor√≠as de sentimiento.
        * Se aplica una **heur√≠stica de coincidencia exacta de palabras clave** para asignaciones de alta confianza, seguida de la clasificaci√≥n por similitud cosenoidal con umbrales de confianza y diferencia de puntuaci√≥n.
* **Tema:**
    * **Modelo:** Se utiliza `paraphrase-multilingual-mpnet-base-v2`, otro modelo **Sentence-BERT multiling√ºe** p√∫blico y de alto rendimiento, ideal para la comprensi√≥n sem√°ntica entre textos en espa√±ol.
    * **Funcionamiento:**
        * Similar al tono, los textos se preprocesan.
        * Se definen **palabras clave para cada tema** (`predefined_keywords`).
        * Los textos y las listas de palabras clave se transforman en embeddings.
        * La clasificaci√≥n se basa en la **similitud cosenoidal**, complementada con una **verificaci√≥n de coincidencia exacta de palabras clave** para mayor precisi√≥n.

### 2. **An√°lisis con Entrenamiento Supervisado**

Este enfoque requiere un conjunto de datos previamente etiquetado para **entrenar un clasificador** que aprenda los patrones espec√≠ficos de tus datos.
* **Tono (Sentimiento):**
    * **Modelo:** Se construye un pipeline con **`CountVectorizer`** para la representaci√≥n de texto (conteo de palabras) y **`LogisticRegression`** como clasificador.
    * **Funcionamiento:**
        * Se carga un archivo de entrenamiento (`.xlsx`) con res√∫menes y sus etiquetas de tono (`Positivo`, `Neutro`, `Negativo`), las cuales se mapean a valores num√©ricos.
        * El dataset se divide en conjuntos de entrenamiento y prueba.
        * El modelo aprende las relaciones entre las palabras y el tono a partir de los datos de entrenamiento.
        * Una vez entrenado, puede predecir el tono de nuevos res√∫menes de noticias.
* **Tema:**
    * **Modelo:** Se utiliza una combinaci√≥n de **`CountVectorizer`** para la vectorizaci√≥n de texto y **`MultinomialNB` (Naive Bayes Multinomial)** para la clasificaci√≥n.
    * **Funcionamiento:**
        * Se carga un archivo de entrenamiento (`.xlsx`) que contiene res√∫menes y sus etiquetas de tema.
        * Los textos son preprocesados (normalizaci√≥n, tokenizaci√≥n, eliminaci√≥n de stopwords en espa√±ol) usando NLTK y expresiones regulares.
        * El modelo se entrena para asociar patrones de palabras con temas espec√≠ficos.
        * Los modelos entrenados (`modelo_naive_bayes.pkl`) y los vectorizadores (`vectorizador.pkl`) se serializan usando **`joblib`** para su posterior uso en inferencia sobre nuevos datos.

---

## üíª Librer√≠as Clave Utilizadas

Este proyecto se apoya en una serie de librer√≠as de Python para su funcionamiento:

* **`pandas`**: Para la manipulaci√≥n y gesti√≥n eficiente de datos tabulares (archivos `.xlsx`).
* **`openpyxl`**: Motor para leer y escribir archivos `.xlsx`.
* **`sentence-transformers`**: Fundamental para el an√°lisis "Zero-Shot", permite cargar y usar modelos pre-entrenados para generar embeddings de texto.
* **`torch`**: (PyTorch) La librer√≠a de deep learning subyacente utilizada por `sentence-transformers` para operaciones en GPU/CPU.
* **`tqdm`**: Para mostrar barras de progreso, lo que mejora la experiencia de usuario durante procesos largos.
* **`emoji`**: Para el manejo de emojis en el preprocesamiento de texto (aunque en noticias su impacto es menor).
* **`re`**: M√≥dulo de expresiones regulares para tareas de limpieza y preprocesamiento de texto.
* **`unicodedata`**: Para la normalizaci√≥n de caracteres en el preprocesamiento de texto.
* **`scikit-learn`**: Colecci√≥n robusta de herramientas para aprendizaje autom√°tico, utilizada en el enfoque supervisado para `CountVectorizer`, `LogisticRegression`, `MultinomialNB`, y m√©tricas de evaluaci√≥n.
* **`nltk`**: (Natural Language Toolkit) Para el procesamiento de lenguaje natural, espec√≠ficamente para el manejo de "stopwords" (palabras comunes sin significado tem√°tico) en el enfoque supervisado de tema.
* **`joblib`**: Para la serializaci√≥n y deserializaci√≥n de modelos entrenados y vectorizadores, permitiendo guardarlos y cargarlos eficientemente.

---

## üõ†Ô∏è Estructura del Proyecto

* `notebooks/`: Contiene los notebooks de Google Colab (`.ipynb`) con la l√≥gica de inferencia para ambos enfoques, as√≠ como los experimentos y an√°lisis originales.
* `data/`: Directorio centralizado para almacenar:
    * Archivos de entrada (`.xlsx`) con las noticias a analizar.
    * Archivos de entrenamiento (`.xlsx`) con noticias previamente codificadas (para el enfoque supervisado).
    * Resultados de las clasificaciones (`.xlsx`).
* `models/`: Directorio dedicado a guardar los modelos entrenados (`.pkl`) y vectorizadores serializados, cuando se utiliza el enfoque supervisado.
* `scripts/`: Scripts Python auxiliares para tareas de procesamiento o predicci√≥n que puedan ser ejecutadas fuera de los notebooks.
* `requirements.txt`: Lista de todas las dependencias del proyecto, √∫til para replicar el entorno localmente.
* `README.md`: Esta documentaci√≥n principal.

---

## üöÄ C√≥mo Empezar

Para poner en marcha este proyecto en tu entorno Google Colab:

1.  **Clona el repositorio:**
    ```bash
    git clone https://github.com/tu_usuario/Zero_Entreno_2025.git
    cd Zero_Entreno_2025
    ```

2.  **Instala las dependencias:**
    * Aunque los notebooks incluyen comandos para la instalaci√≥n silenciosa (`!pip install -qq ...`), si deseas un entorno local, puedes instalar todas las dependencias desde el archivo `requirements.txt`:
        ```bash
        pip install -r requirements.txt
        ```

3.  **Prepara tus datos:**
    * Para cualquier an√°lisis, tus archivos de entrada (`.xlsx`) deben contener una columna nombrada `resumen` con el texto a procesar.
    * Si utilizas el modo con entrenamiento, los notebooks te indicar√°n c√≥mo subir los archivos `.xlsx` de entrenamiento (noticias previamente analizadas) y los archivos `.xlsx` de prueba (nuevas noticias a analizar).

4.  **Ejecuta el an√°lisis:**
    * Abre los notebooks relevantes en la carpeta `notebooks/` en Google Colab.
    * Sigue las instrucciones espec√≠ficas dentro de cada notebook para ejecutar el an√°lisis de tono o tema, y para seleccionar el enfoque (Zero-Shot o con entrenamiento) deseado.
    * Para el modo Zero-Shot, puedes personalizar las listas de "temas a inferir" o "palabras clave de sentimiento" directamente en el c√≥digo del notebook.

---

## ü§ù Contribuci√≥n

¬°Tu contribuci√≥n es muy valorada! Si tienes ideas para mejorar el proyecto, encuentras alg√∫n error o deseas a√±adir nuevas funcionalidades, por favor:

1.  Abre un `issue` para discutir tu propuesta.
2.  Env√≠a un `pull request` con tus cambios.

---
